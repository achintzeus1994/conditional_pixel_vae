{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncMNIST(nn.Module):\n",
    "    def __init__(self, latent_dim_mnist):\n",
    "        super(EncMNIST, self).__init__()\n",
    "        self.latent_dim_mnist = latent_dim_mnist\n",
    "        self.dim_MNIST = 28 * 28\n",
    "\n",
    "        self.enc = nn.Sequential(nn.Linear(self.dim_MNIST, 512),\n",
    "                                 nn.ReLU(inplace=True), \n",
    "                                 nn.Linear(512, 128),\n",
    "                                 nn.ReLU(inplace=True))\n",
    "        self.enc_mu_mnist = nn.Linear(128, latent_dim_mnist)\n",
    "        self.enc_var_mnist = nn.Linear(128, latent_dim_mnist)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        mu_mnist = self.enc_mu_mnist(x)\n",
    "        log_var_mnist = self.enc_var_mnist(x)\n",
    "        return mu_mnist, log_var_mnist\n",
    "    \n",
    "class DecMNIST(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(DecMNIST, self).__init__()  \n",
    "        self.latent_dim = latent_dim + 10\n",
    "        self.dim_MNIST   = 28 * 28\n",
    "        \n",
    "        self.dec = nn.Sequential(nn.Linear(self.latent_dim, 128), \n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Linear(128, 512), \n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Linear(512, self.dim_MNIST), \n",
    "                                 nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, z,x,generate_mode):\n",
    "#         return self.dec(z).reshape(-1, 1, 28, 28).to(z.device)\n",
    "        return self.dec(z).to(device)\n",
    "    \n",
    "    \n",
    "class pixelcnn_decoder(nn.Module):\n",
    "    def __init__(self, pixelcnn):\n",
    "        super(pixelcnn_decoder, self).__init__()\n",
    "        self.pixelcnn = pixelcnn\n",
    "\n",
    "    def forward(self, z, img,generate_mode):\n",
    "        img_out = img.reshape(z.shape[0],1,28,28).to(z.device)\n",
    "        if generate_mode is False:\n",
    "            sample = self.pixelcnn(img_out, z )\n",
    "        else:\n",
    "            shape = [1,28,28]\n",
    "            count = z.shape[0]\n",
    "            sample = self.pixelcnn.sample(img_out,shape,count, z )\n",
    "#             sample = self.pixelcnn(img_out, z )\n",
    "\n",
    "        return (sample, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "achint-env",
   "language": "python",
   "name": "achint-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
